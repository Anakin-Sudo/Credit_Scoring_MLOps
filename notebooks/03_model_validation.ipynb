{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook 03 â€“ Model Validation\n",
    "\n",
    "Objective:  \n",
    "- Run cross-validation for candidate models (LogReg, RF, XGBoost).  \n",
    "- Evaluate using credit scoring metrics (ROC AUC, recall, precision, F1, accuracy, precision@k).  \n",
    "- Select top hyperparameter configurations.  \n",
    "- Export candidate definitions to `configs/training_candidates.yaml` for pipeline training.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae8e9b12cd01b3ff"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-01T19:42:35.067146100Z",
     "start_time": "2025-09-01T19:42:30.708757200Z"
    }
   },
   "id": "aa890680da546c77"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(['Duration',\n  'CreditAmount',\n  'InstallmentRate',\n  'ResidenceSince',\n  'Age',\n  'ExistingCredits',\n  'PeopleLiable'],\n ['OtherDetors',\n  'OtherInstallmentPlans',\n  'Housing',\n  'Telephone',\n  'ForeignWorker'],\n ['Status',\n  'CreditHistory',\n  'Purpose',\n  'Savings',\n  'Employment',\n  'SexAndStatus',\n  'Property',\n  'Job'])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset (curated version with decoded categories)\n",
    "df = pd.read_csv(\"../german_credit.csv\")\n",
    "\n",
    "X = df.drop(\"CreditRisk\", axis=1)\n",
    "y = df[\"CreditRisk\"]\n",
    "\n",
    "# Load feature groups (saved from Notebook 01)\n",
    "import json\n",
    "with open(\"../configs/feature_groups.json\", \"r\") as f:\n",
    "    feature_groups = json.load(f)\n",
    "\n",
    "num_cols = feature_groups[\"num_cols\"]\n",
    "simple_cat_cols = feature_groups[\"simple_cat_cols\"]\n",
    "complex_cat_cols = feature_groups[\"complex_cat_cols\"]\n",
    "\n",
    "num_cols, simple_cat_cols, complex_cat_cols"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-01T19:42:37.537462200Z",
     "start_time": "2025-09-01T19:42:37.380292900Z"
    }
   },
   "id": "81ba91a63b4ef30e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "((800, 20), (200, 20))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-test split (stratified, consistent with preprocessing component)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-01T19:44:08.723247300Z",
     "start_time": "2025-09-01T19:44:08.644361600Z"
    }
   },
   "id": "c0a8af178dad828a"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Numeric pipeline: impute median + scale\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Simple categorical pipeline: impute most frequent + one-hot encode\n",
    "simple_cat_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "# Complex categorical pipeline: impute most frequent + target encode\n",
    "complex_cat_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"targetenc\", TargetEncoder())\n",
    "])\n",
    "\n",
    "# Combine everything into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipeline, num_cols),\n",
    "        (\"simple_cat\", simple_cat_pipeline, simple_cat_cols),\n",
    "        (\"complex_cat\", complex_cat_pipeline, complex_cat_cols),\n",
    "    ]\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-01T19:44:11.192627500Z",
     "start_time": "2025-09-01T19:44:11.160833400Z"
    }
   },
   "id": "81e32dabbc03051"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Compute scale_pos_weight for XGB\n",
    "n_neg = (y_train == 0).sum()\n",
    "n_pos = (y_train == 1).sum()\n",
    "scale_pos_weight = n_neg / n_pos\n",
    "\n",
    "models_and_grids = {\n",
    "    \"logreg\": (\n",
    "        LogisticRegression(max_iter=1000, solver=\"liblinear\", class_weight=\"balanced\"),\n",
    "        {\n",
    "            \"model__C\": [0.01, 0.1, 1, 10],\n",
    "            \"model__penalty\": [\"l1\", \"l2\"]\n",
    "        }\n",
    "    ),\n",
    "    \"rf\": (\n",
    "        RandomForestClassifier(random_state=42, class_weight=\"balanced\"),\n",
    "        {\n",
    "            \"model__n_estimators\": [100, 200],\n",
    "            \"model__max_depth\": [None, 5, 10],\n",
    "            \"model__min_samples_split\": [2, 5]\n",
    "        }\n",
    "    ),\n",
    "    \"xgb\": (\n",
    "        XGBClassifier(\n",
    "            eval_metric=\"auc\",  # no more 'use_label_encoder'\n",
    "            random_state=42,\n",
    "            scale_pos_weight=scale_pos_weight\n",
    "        ),\n",
    "        {\n",
    "            \"model__n_estimators\": [100, 200],\n",
    "            \"model__max_depth\": [3, 5],\n",
    "            \"model__learning_rate\": [0.1, 0.01],\n",
    "            \"model__subsample\": [0.8, 1.0]\n",
    "        }\n",
    "    )\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-01T19:51:37.935619500Z",
     "start_time": "2025-09-01T19:51:37.825080600Z"
    }
   },
   "id": "51d1fb5c10fd017f"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running CV for logreg...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best CV ROC AUC for logreg: 0.779\n",
      "Running CV for rf...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best CV ROC AUC for rf: 0.790\n",
      "Running CV for xgb...\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best CV ROC AUC for xgb: 0.792\n"
     ]
    }
   ],
   "source": [
    "cv_results = []\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for model_name, (estimator, param_grid) in models_and_grids.items():\n",
    "    print(f\"Running CV for {model_name}...\")\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", estimator)\n",
    "    ])\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring=\"roc_auc\",\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Log results\n",
    "    best_params = grid.best_params_\n",
    "    best_score = grid.best_score_\n",
    "    print(f\"Best CV ROC AUC for {model_name}: {best_score:.3f}\")\n",
    "    \n",
    "    cv_results.append({\n",
    "        \"model\": model_name,\n",
    "        \"best_params\": best_params,\n",
    "        \"cv_score\": best_score\n",
    "    })\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-01T19:52:57.860707600Z",
     "start_time": "2025-09-01T19:51:40.449668600Z"
    }
   },
   "id": "24a31a476ee5858e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "    model                                        best_params  cv_score\n2     xgb  {'model__learning_rate': 0.1, 'model__max_dept...  0.791778\n1      rf  {'model__max_depth': 5, 'model__min_samples_sp...  0.789918\n0  logreg           {'model__C': 10, 'model__penalty': 'l2'}  0.779464",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>best_params</th>\n      <th>cv_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>xgb</td>\n      <td>{'model__learning_rate': 0.1, 'model__max_dept...</td>\n      <td>0.791778</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>rf</td>\n      <td>{'model__max_depth': 5, 'model__min_samples_sp...</td>\n      <td>0.789918</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>logreg</td>\n      <td>{'model__C': 10, 'model__penalty': 'l2'}</td>\n      <td>0.779464</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "[{'model': 'xgb',\n  'best_params': {'model__learning_rate': 0.1,\n   'model__max_depth': 3,\n   'model__n_estimators': 100,\n   'model__subsample': 1.0},\n  'cv_score': 0.7917782738095238},\n {'model': 'rf',\n  'best_params': {'model__max_depth': 5,\n   'model__min_samples_split': 2,\n   'model__n_estimators': 200},\n  'cv_score': 0.7899181547619049}]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_df = pd.DataFrame(cv_results).sort_values(by=\"cv_score\", ascending=False)\n",
    "display(cv_results_df)\n",
    "\n",
    "# Select top 2 candidates\n",
    "top_candidates = cv_results_df.head(2).to_dict(orient=\"records\")\n",
    "top_candidates\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-01T19:52:57.968799900Z",
     "start_time": "2025-09-01T19:52:57.843574800Z"
    }
   },
   "id": "4e7739f11eb5ff96"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../configs/training_candidates.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"selection_metric\": \"roc_auc\",\n",
    "        \"acceptance_criteria\": {\"min_roc_auc\": 0.70},\n",
    "        \"candidates\": top_candidates\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"Top candidates exported to configs/training_candidates.json\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c2ef9e5e4b6b6eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
